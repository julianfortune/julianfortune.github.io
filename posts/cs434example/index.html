<!DOCTYPE html>
<html lang="en">

<meta charset="utf-8" />

<title>Implementation Assignment 4 - Julian Fortune</title>

<meta name="description" content="Introduction This assignment is focused on unsupervised learning, using data from the accelerometer and gyroscope in Samsung devices. Each training example had an corresponding classification for the activity in which device&rsquo;s owner was engaged.
Unsupervised clustering allows us to separate data points into a chosen number of classes without any knowledge of the ground truth classes themselves. This is useful for dividing data into groups which cannot be easily described or which may not even be known to exist.">
<meta name="author" content="">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">







    
    
    
    <link rel="stylesheet" href="/style.min.css" media="screen">




<script>
    function toggleMenu() {
        var x = document.getElementById("navigation");
        if (x.className === "") {
            x.className = "open";
        } else {
            x.className = "";
        }
    }
</script><body>
        <header><nav class="" id="navigation">
    <div class="top-bar">
        <a class="logo" href="/">
            <h1>
                Julian Fortune
            </h1>
        </a><ul>
    
    
    
    <li class="">
        <a href="/about/" title="About">
            About
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class=" active ">
        <a href="/posts/" title="Blog">
            Blog
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class="">
        <a href="/projects/" title="Projects">
            Projects
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class="">
        <a href="/publications/" title="Publications">
            Publications
        </a>
        <div class="underline"></div>
    </li>
    
</ul><div class="open-menu-button" title="Open Navigation Menu" onclick="toggleMenu()">
            <div class="menu-button-container">
                <div class="icon"></div>
                <div class="icon"></div>
                <div class="icon"></div>
            </div>
        </div>
    </div>
    <div class="dropdown-menu"><ul>
    
    
    
    <li class="">
        <a href="/about/" title="About">
            About
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class=" active ">
        <a href="/posts/" title="Blog">
            Blog
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class="">
        <a href="/projects/" title="Projects">
            Projects
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class="">
        <a href="/publications/" title="Publications">
            Publications
        </a>
        <div class="underline"></div>
    </li>
    
</ul></div>


</nav></header>

<main>
    <article class="content">
        <header>
            <h1 class="title">
                Implementation Assignment 4
            </h1>
            <p class="date">
                
            </p>
        </header>
        <h2 id="introduction">Introduction</h2>
<p>This assignment is focused on unsupervised learning, using data from the accelerometer and gyroscope in Samsung devices.
Each training example had an corresponding classification for the activity in which device&rsquo;s owner was engaged.</p>
<p>Unsupervised clustering allows us to separate data points into a chosen number of classes without any knowledge of the ground truth classes themselves. This is useful for dividing data into groups which cannot be easily described or which may not even be known to exist. There are many practical applications. One example is targeted marketing, wherein the audience is assigned to clusters based on their characteristics, and each cluster is assigned a particular marketing strategy which is known to be affective toward people with the general characteristics of the cluster.</p>
<p>The data from the Samsung devices has over 500 dimensions, which encourages unnecessarily complex models, and is impractical to visualize.
Unsupervised principal component analysis reduces the number of dimensions by iteratively selecting new dimensions that maximally capture the variation in the data until we have retained a set proportion of the original variation.
By selecting the first two dimensions we can plot the data in a scatterplot, and by transforming the data into the lower dimensional space can reduce overfitting in models.</p>
<h2 id="1-clustering">1. Clustering</h2>
<p>The data for figures 1, 2, and 3 can be generated by running the following command from the <code>src</code> directory:</p>
<pre><code>python3 main.py
</code></pre><p>Figure 3 depicts the purity versus <code>k</code> in k-means clustering with 20 iterations. If the SSE is to be considered inversely related to the k-means clustering performance, purity can be considered positively correlated to the performance. Purity is a simple measure of the proportion of training samples which are members of the majority class in their respective clusters. In other words, if the majority class of a cluster is used to predict the classes of every sample point in said cluster, the purity is the proportion of correctly classified samples across all clusters. As purity is inversely related to the SSE, it is not surprising that purity will increase to 1 (or 100% accuracy) as <code>k</code> approaches the size of the training set, just as SSE decreases to zero. Similarly, it is also not surprising that k-means clustering iterations induce a non-decreasing effect on purity.</p>
<h2 id="2-principle-component-analysis">2. Principle Component Analysis</h2>
<h3 id="1-implementation">1. Implementation</h3>
<p>We implemented the algorithm presented in class for unsupervised principal component analysis (PCA).
The code can be found in lines <code>65–93</code> in <code>decompose.py</code>.</p>
<h3 id="2-visualization">2. Visualization</h3>
<p>Principal component analysis produces a set of axes in descending order of variation retained. By plotting the first two axes—the most meaningful axes—we can visualize the data in two dimensions. Despite losing some amount of information, typically the axes that retain little information are mostly noise, the data can now be meaningfully visualized. The graph of the first principal component axes (PC 1) against the second principal component axes (PC 2) if shown in Figure 4.</p>
<p>The graph can be reproduced by running the command:</p>
<pre><code>python3 main.py --pca 1 --kmeans 0
</code></pre><h3 id="3-dimensions">3. Dimensions</h3>
<p>PCA reduced the data to <code>34</code> dimensions when using a retain ratio of <code>0.9</code>.
This gives an indication that many of the dimensions are extraneous or noisy, because almost all of the variation of the data can be captured in around one fifteenth of the original number of axes.</p>
<p>In order to verify for yourself, run:</p>
<pre><code>python3 main.py --pca 1 --kmeans 0
</code></pre><h3 id="4-k-means-revisited">4. k-means Revisited</h3>
<p>We can return to k-means to assess the performance of k-means when principal component analysis is introduced as a preprocessing step.</p>
<pre><code>python3 main.py --pca 1
</code></pre><p>With a ratio of <code>0.99</code>, PCA reduced the data to <code>155</code> dimensions, while achieving purities very close the those without any dimension reduction, shown in Figure 7.</p>

    </article>
</main>



        <footer><center>
    <p>
        <span>&copy; 2020
            
        </span>
        <span>&middot;</span>
        <span>Powered by <a class="hugo-link" href="https://gohugo.io">Hugo</a></span>
        
    </p>
</center></footer>
    </body>
</html>
