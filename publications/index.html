<!DOCTYPE html>
<html lang="en">

<meta charset="utf-8" />

<title>Publications - Julian Fortune</title>

<meta name="description" content="">
<meta name="author" content="">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">







    
    
    <link rel="stylesheet" href="/style.min.css" media="screen">






<script src="/js/zooming.js"></script>

<script>
    function toggleMenu() {
        var x = document.getElementById("navigation");
        if (x.className === "") {
            x.className = "open";
        } else {
            x.className = "";
        }
    }

    
    document.addEventListener('DOMContentLoaded', function () {
        new Zooming({
            
            scaleBase: 0.8,
            enableGrab: false,
            bgColor: "none",
        }).listen('.img-zoomable')
    })
</script><body>
        <header><nav class="" id="navigation">
    <div class="top-bar">
        <a class="logo" href="/">
            <h1>
                Julian Fortune
            </h1>
        </a><ul>
    
    
    
    <li class="">
        <a href="/about/" title="About">
            About
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class="">
        <a href="/projects/" title="Projects">
            Projects
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class=" active ">
        <a href="/publications/" title="Publications">
            Publications
        </a>
        <div class="underline"></div>
    </li>
    
</ul><div class="open-menu-button" title="Open Navigation Menu" onclick="toggleMenu()">
            <div class="menu-button-container">
                <div class="icon"></div>
                <div class="icon"></div>
                <div class="icon"></div>
            </div>
        </div>
    </div>
    <div class="dropdown-menu"><ul>
    
    
    
    <li class="">
        <a href="/about/" title="About">
            About
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class="">
        <a href="/projects/" title="Projects">
            Projects
        </a>
        <div class="underline"></div>
    </li>
    
    
    <li class=" active ">
        <a href="/publications/" title="Publications">
            Publications
        </a>
        <div class="underline"></div>
    </li>
    
</ul></div>


</nav></header>

<main class="content list publications">
    <h1 class="center">
        Publications
    </h1>
    <ul class="center">
    
        <li class="preview">
            
                <a class="title" href="/publications/hfes2020/" title="Real-Time Speech Workload Estimation for Intelligent Human-Machine Systems">
            
                    <h1>
                        Real-Time Speech Workload Estimation for Intelligent Human-Machine Systems
                    </h1>
                </a>
            
                <p class="publisher shaded">
                    Accepted to the Human Factors and Ergonomics Society Annual Meeting
                </p>
            
            
                <p class="authors">
                    Julian Fortune, Dr. Jamison Heard, and Dr. Julie A. Adams
                </p>
            
            
                <p class="description shaded">
                    Demanding task environments (e.g., supervising a remotely piloted aircraft) require performing tasks quickly and accurately; however, periods of low and high operator workload can decrease task performance. Intelligent modulation of the system’s demands and interaction modality in response to changes in operator workload state may increase performance by avoiding undesirable workload states. This system requires real-time estimation of each workload component (i.e., cognitive, physical, visual, speech, and auditory) to adapt the correct modality. Existing workload systems estimate multiple workload components post-hoc, but none estimate speech workload, or function in real-time. This manuscript presents an algorithm to estimate speech workload and mitigate undesirable workload states in real-time. The adaptive system uses the algorithm’s estimates to mitigate under/overload, a crucial step towards adaptive machine-human systems.
                </p>
            
            
                <p class="link">
                    
                    
                    
                        <a href="/documents/HFES2020Presentation.pdf" title="Real-Time Speech Workload Estimation for Intelligent Human-Machine Systems presentation">Slides</a>
                    
                </p>
            
        </li>
    
        <li class="preview">
            
                <a class="title" href="https://ir.library.oregonstate.edu/concern/honors_college_theses/2v23w1844" title="Real-time Speech Workload Estimation">
            
                    <h1>
                        Real-time Speech Workload Estimation
                    </h1>
                </a>
            
                <p class="publisher shaded">
                    Oregon State University Honors College, 2020
                </p>
            
            
            
                <p class="description shaded">
                    Demanding task environments (eg, supervising a remotely piloted aircraft) require performing tasks quickly and accurately; however, periods of low and high operator workload can decrease task performance. Intelligent modulation of the system’s demands and interaction modality in response to changes in operator workload state may increase performance by avoiding undesirable workload states. This system requires real-time estimation of each workload component (ie, cognitive, physical, visual, speech, and auditory) to adapt the correct modality. Existing workload systems estimate multiple workload components post-hoc, but none estimate speech workload, or function in real-time. This thesis presents an algorithm to estimate speech workload and mitigate undesirable workload states in real-time. The results from an analysis of the algorithm’s accuracy are presented, along with the results from evaluating the algorithm’s generalizability across individuals, human-machine teaming paradigms, and task environments (stationary and non-stationary). The ideal window sizes for real-time and offline use were determined. Results were presented from an assessment of the impact on performance resulting from adding physiological data and filler utterances to the base set of features. Real-time speech workload estimation is a crucial step towards adaptive human-machine systems.
                </p>
            
            
                <p class="link">
                    
                        <a href="https://ir.library.oregonstate.edu/downloads/m613n447j" title="Real-time Speech Workload Estimation full text">Full text</a>
                    
                    
                        <a href="/documents/ThesisPoster.pdf" title="Real-time Speech Workload Estimation poster">Poster</a>
                    
                    
                        <a href="/documents/ThesisPresentation.pdf" title="Real-time Speech Workload Estimation presentation">Slides</a>
                    
                </p>
            
        </li>
    
        <li class="preview">
            
                <a class="title" href="https://arxiv.org/abs/2003.05823" title="SAHRTA: A Supervisory-Based Adaptive Human-Robot Teaming Architecture">
            
                    <h1>
                        SAHRTA: A Supervisory-Based Adaptive Human-Robot Teaming Architecture
                    </h1>
                </a>
            
                <p class="publisher shaded">
                    IEEE Conference on Cognitive and Computational Aspects of Situation Management, 2019
                </p>
            
            
                <p class="authors">
                    Dr. Jamison Heard, Julian Fortune, and Dr. Julie A. Adams
                </p>
            
            
                <p class="description shaded">
                    Supervisory-based human-robot teams are deployed in various dynamic and extreme environments (eg, space exploration). Achieving high task performance in such environments is critical, as a mistake may lead to significant monetary loss or human injury. Task performance may be augmented by adapting the supervisory interface&#39;s interactions or autonomy levels based on the human supervisor&#39;s workload level, as workload is related to task performance. Typical adaptive systems rely solely on the human&#39;s overall or cognitive workload state to select what adaptation strategy to implement; however, overall workload encompasses many dimensions (ie, cognitive, physical, visual, auditory, and speech) called workload components. Selecting an appropriate adaptation strategy based on a complete human workload state (rather than a single workload dimension) may allow for more impactful adaptations that ensure high task performance. A Supervisory-Based Adaptive Human-Robot Teaming Architecture (SAHRTA) that selects an appropriate level of autonomy or system interaction based on a complete real-time multi-dimensional workload estimate and predicted future task performance is introduced. SAHRTA was shown to improve overall task performance in a physically expanded version of the NASA Multi-Attribute Task Battery.
                </p>
            
            
                <p class="link">
                    
                        <a href="https://arxiv.org/pdf/2003.05823.pdf" title="SAHRTA: A Supervisory-Based Adaptive Human-Robot Teaming Architecture full text">Full text</a>
                    
                    
                    
                </p>
            
        </li>
    
        <li class="preview">
            
                <a class="title" href="https://journals.sagepub.com/doi/abs/10.1177/1071181319631018" title="Speech Workload Estimation for Human-Machine Interaction">
            
                    <h1>
                        Speech Workload Estimation for Human-Machine Interaction
                    </h1>
                </a>
            
                <p class="publisher shaded">
                    Human Factors and Ergonomics Society Annual Meeting, 2019
                </p>
            
            
                <p class="authors">
                    Dr. Jamison Heard, Julian Fortune, and Dr. Julie A. Adams
                </p>
            
            
                <p class="description shaded">
                    Performing tasks quickly and accurately in dynamic and intense environments is critical, such as supervising a remotely piloted aircraft; however, these environments contain periods of low and high workload, which can decrease task performance. A system capable of intelligently adapting its interaction modality based on the human’s workload state may mitigate these undesirable workload states: underload and overload. Such a system requires mechanisms to determine accurately the human’s overall workload state and each workload component state (i.e., cognitive, physical, visual, speech, and auditory) in order to understand the current workload state’s underlying cause effectively. Existing work estimates multiple workload components, but no method estimates speech workload. This manuscript presents an algorithm for accurately estimating a human’s speech workload level using methods suitable for real-time workload assessment. The algorithm is an essential component to future adaptive human-machine interfaces.
                </p>
            
            
                <p class="link">
                    
                        <a href="https://journals.sagepub.com/doi/pdf/10.1177/1071181319631018" title="Speech Workload Estimation for Human-Machine Interaction full text">Full text</a>
                    
                    
                    
                </p>
            
        </li>
    
    </ul>
</main>



        <footer><center>
    <p>
        <span>&copy; 2021
            
        </span>
        <span>&middot;</span>
        <span>Powered by <a class="hugo-link" href="https://gohugo.io">Hugo</a></span>
        
    </p>
</center></footer>
    </body>
</html>
